\subsection{Redes Neurais Artificiais}

Redes Neurais Artificiais são sistemas paralelos distribuídos compostos por unidades de processamento simples que executam cálculos matemáticos. Essas unidades são dispostas em uma ou mais camadas e são interligadas por um grande número de conexões, normalmente unidirecionais. As conexões possuem pesos que armazenam o conhecimento adquirido pelo modelo. RNAs têm como procedimento usual uma etapa de aprendizagem, onde um conjunto de exemplos é apresentado a ela. A rede então aprende e generalização a informação \cite{bib-braga}.

\subsection{Backpropagation}

Backpropagation é um algoritmo utilizado para o treinamento de Redes MLP, Multi-Layer-Perceptron. Esse método utiliza o gradiente descendente para calcular o erro das camadas intermediárias através de uma estimativa do efeito que elas causam na camada de saída. No algoritmo, o erro na saída é calculado e é então retroalimentado para as camadas intermediárias, possibilitando o ajuste dos pesos proporcionalmente aos valores das conexões entre as camadas.

\subsection{Scaled Conjugate Gradient}

O algoritmo SCG, Scaled Conjugate Gradient, é um algoritmo de aprendizado supervisionado com taxa de convergência superlinear. Ele utiliza uma técnica de otimização baseada no Gradiente Conjungado. \cite{bib-moller}

\subsection{Confusion Matrix}

A Confusion Matrix, também conhecida como Error Matrix, é uma tabela que permite a visualização da performance de um algoritmo de classificação. Nas colunas são representadas as classes reais e nas linhas as classes calculadas pela rede. Assim, cada célula da matriz representa o cruzamento entre a quantidade real de casos e a quantidade encontrado dos casos. Por consequência, a diagonal principal  da matriz irá representar a quantidade de acertos da rede.